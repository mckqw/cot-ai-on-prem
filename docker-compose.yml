version: '3.8'

services:
  server:
    build: .
    # runtime: nvidia  # Remove this line if not using an NVIDIA GPU
    ports:
      - "8000:8000"
    volumes:
      - /Users/matthew.h.clark/.cache/huggingface/hub/:/models  # Update with the actual path to your model files
    environment:
      - MODEL_PATH=/Users/matthew.h.clark/.cache/huggingface/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-32B
    command: python main.py server

  client:
    build: .
    stdin_open: true
    tty: true
    environment:
      - SERVER_URL=http://server:8000/query
    command: python main.py tts
    depends_on:
      - server

  evaluate:
    build: .
    environment:
      - SERVER_URL=http://server:8000
    depends_on:
      - server
    command: python evaluate.py